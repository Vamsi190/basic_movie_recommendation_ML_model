{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2903f0fc-f4f0-4655-9715-63f7ce1c97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie recommendation ML model (For Netflix, prime etc)\n",
    "\n",
    "# 1. First we build the model and feed it sample data based on the existing users.\n",
    "# 2. Our model will learn the patterns in our data so that we can ask it to make predictions\n",
    "# 3. When a new user signs up, we ask our model, \"Hey Weh have a new user with this profile. What kind of movies that this user will be interested in?\"\n",
    "# 4. Our model might then state or recommend : \"Action movies\", \"Docuentaries\" etc.\n",
    "\n",
    "# The process to be followed:\n",
    "# 1. Import the data\n",
    "# 2. Clean the data\n",
    "# 3. Split the data into training/ test sets\n",
    "# 4. Create a model\n",
    "# 5. Train the model\n",
    "# 6. Make predictions\n",
    "# 7. Evaluate and Improve\n",
    "\n",
    "\n",
    "# As per the recommended amount for testing the accuracy , for testing : 20% of the dataset should be used and for training we have to use the rest of the 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c6c47ac-e9a2-4ceb-886f-cbf00b8a396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Import the data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The train_test_split will help us split the dataset into two sets, one for training and one for testing\n",
    "\n",
    "movies_data = pd.read_csv(\"movies.csv\")\n",
    "X = movies_data.drop(columns = ['genre'])# X indicates input dataset, drop here make another dataset without the genre column\n",
    "y = movies_data['genre']# y is the output dataset\n",
    "x_train , x_test, y_train , y_test = train_test_split(X,y, test_size=0.2) # is the keyword argument that specifies the size of our test dataset, here 0.2 in other words means that we are allocating 20% of our dataset for testing\n",
    "\n",
    "# When the above split is called , it will end up giving a tuple\n",
    "\n",
    "model = DecisionTreeClassifier() #This is the ML algo from sckit that will help us perform the predictions\n",
    "model.fit(x_train.values, y_train.values)# This method called fit takes two datasets, input dataset and output dataset\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test.values)# This takes a two dimensional array, 21 years and 1 -male\n",
    "score = accuracy_score(y_test, predictions)\n",
    "score \n",
    "\n",
    "# To get the accuracy of the model , we will compare the predictions given by the model with the actual values of y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "280e06e1-3359-47b8-9c99-aced0a88ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Documentary'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Model Perisistance\n",
    "# 1.As soon as we train our model, we save it to a file.\n",
    "# 2.Next time we want to make predictions, we simply load the model from the file and ask it to make predictions\n",
    "# 3.We can do that because that model is already trained. So we do not have to re-train it again again.\n",
    "# 4.The file acts like snapshot of a skilled professional --once they have mastered a task, you can call on them anytime to perform it without\n",
    "# needing to retrain or reteach them everytime.\n",
    "\n",
    "#1. Import the data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib # The package has methods for saving and loading models\n",
    "\n",
    "# The train_test_split will help us split the dataset into two sets, one for training and one for testing\n",
    "\n",
    "# movies_data = pd.read_csv(\"movies.csv\")\n",
    "# X = movies_data.drop(columns = ['genre'])# X indicates input dataset, drop here make another dataset without the genre column\n",
    "# y = movies_data['genre']# y is the output dataset\n",
    "\n",
    "# model = DecisionTreeClassifier()\n",
    "# model.fit(x_train.values, y_train.values)# This method called fit takes two datasets, input dataset and output dataset\n",
    "\n",
    "model = joblib.load('movie-recommender.joblib')\n",
    "predictions = model.predict([[29,0]])\n",
    "predictions\n",
    "\n",
    "\n",
    "# What is Joblib?\n",
    "# 1. To put it simply , it is a binary file.\n",
    "# 2. It saves the model in a compressed, effiicient binary format, which makes it faster to store and load, especially for larger models\n",
    "# or datasets.\n",
    "# 3. It is great because it is fast and handles large models well.\n",
    "\n",
    "# predictions = model.predict(x_test.values)# This takes a two dimensional array, 21 years and 1 -male\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55fb2822-42f7-4bae-ae9d-2e7f1314244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising decision trees\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "movies_data = pd.read_csv(\"movies.csv\")\n",
    "X = movies_data.drop(columns = ['genre'])# X indicates input dataset, drop here make another dataset without the genre column\n",
    "y = movies_data['genre']\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X.values, y.values)\n",
    "\n",
    "tree.export_graphviz(model,out_file = 'movies-recommender.dot', feature_names=['age','gender'], class_names = sorted(y.unique()), label = 'all', rounded=True, filled=True)\n",
    "\n",
    "# 1. feature_names:\n",
    "# It tells the model what each input represents. In our case, we have two inputs-'age' and 'gender'.\n",
    "# By passing these as feature_names, we ensure the decision tree uses these labels when showing how it splits and makes decisions.\n",
    "\n",
    "# 2.class_names :\n",
    "# class_names tells the model what each possible prediction is. In our case the model predicts movie genres, like 'Action', 'Sci-Fi','Drama' etc \n",
    "# By passing these as class_names, we can see these labels in the decision tree, showing which genre the model predicts at each step.\n",
    "\n",
    "# filled - fills the node with color\n",
    "# rounded - nodes to have rounded corners\n",
    "# label - to label all the nodes in the decision trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
